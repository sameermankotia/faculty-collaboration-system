Title: Machine Learning Methods for Causal Inference in Economics

Authors:
Sarah Johnson, Department of Economics, Stanford University
Robert Brown, Department of Statistics, Stanford University

Abstract:
This paper examines the application of machine learning methods to causal inference problems in economics. We survey recent methodological advances that combine the predictive power of machine learning with econometric frameworks for identifying causal effects. The methods discussed include double/debiased machine learning, causal forests, orthogonal random forests, and deep instrumental variables. We provide empirical applications demonstrating how these methods can be used to estimate heterogeneous treatment effects in economics research, with a particular focus on policy evaluation and labor economics. Our findings suggest that machine learning approaches can substantially improve causal estimation in settings with high-dimensional controls, complex treatment effect heterogeneity, and large datasets, while maintaining the statistical guarantees required for valid causal inference.

Introduction:
Causal inference stands at the core of empirical economics research, allowing researchers to move beyond correlation to identify the effects of interventions, policies, and economic variables on outcomes of interest. Traditional econometric methods for causal inference, such as instrumental variables, differences-in-differences, and regression discontinuity designs, have been foundational to the field but face limitations when applied to modern, high-dimensional datasets.

The rapid development of machine learning has introduced powerful tools for prediction that can complement traditional econometric approaches. However, naively applying machine learning methods to causal questions can lead to mistaken inferences, as most machine learning algorithms are optimized for prediction rather than parameter estimation. Recent methodological advances have bridged this gap, developing approaches that leverage the predictive power of machine learning while maintaining the statistical properties necessary for valid causal inference.

This paper surveys these developments, focusing on methods that combine machine learning with econometric frameworks to estimate causal effects. We discuss the theoretical foundations of these approaches, their practical implementation, and empirical applications that demonstrate their utility for economic research.

Theoretical Framework:
Causal inference in economics typically revolves around estimating parameters that have a causal interpretation, such as average treatment effects (ATE), treatment effects on the treated (TOT), or local average treatment effects (LATE). The fundamental challenge of causal inference is addressing the potential outcomes that are not observed—the counterfactual outcomes that would have occurred in the absence of treatment for treated units, or under treatment for control units.

The potential outcomes framework provides a conceptual foundation for causal inference. Let Yi(0) and Yi(1) represent the potential outcomes for unit i under control and treatment conditions, respectively. The observed outcome Yi = WiYi(1) + (1-Wi)Yi(0), where Wi is the treatment indicator. The average treatment effect is defined as ATE = E[Yi(1) - Yi(0)].

Selection bias arises when treatment assignment is correlated with potential outcomes, making simple comparisons of treated and control groups misleading. Econometric methods for causal inference typically rely on assumptions such as conditional independence (selection on observables), valid instruments, or local randomization to address this challenge.

Machine learning methods can enhance these approaches by:
1. Flexibly modeling the relationship between outcomes, treatments, and high-dimensional covariates
2. Discovering complex heterogeneity in treatment effects
3. Reducing researcher degrees of freedom in model specification
4. Efficiently handling large datasets with many potential confounders

Methods:
1. Double/Debiased Machine Learning:
   Developed by Chernozhukov et al. (2018), double machine learning addresses the challenge of estimating treatment effects when controlling for high-dimensional confounders. The approach uses sample splitting and orthogonalization to separate the estimation of nuisance parameters (outcome and treatment models) from the estimation of treatment effects.

   The key innovation is the use of Neyman-orthogonal moments, which make the treatment effect estimator robust to errors in the estimation of nuisance parameters. This allows for the use of flexible machine learning methods to estimate these nuisance functions while maintaining valid inference on the parameter of interest.

   Implementation typically involves:
   - Cross-fitting to avoid overfitting
   - Using machine learning methods (random forests, lasso, neural networks) to estimate nuisance functions
   - Constructing orthogonal moments for the parameter of interest

2. Causal Forests:
   Building on random forests, causal forests (Wager and Athey, 2018) provide a method for estimating heterogeneous treatment effects. Unlike standard regression forests that minimize prediction error, causal forests are designed to maximize the precision of treatment effect estimates.

   The method works by:
   - Recursively partitioning the covariate space
   - Estimating treatment effects within each leaf of the resulting tree
   - Aggregating estimates across multiple trees

   Causal forests have several appealing properties, including asymptotic normality and honest confidence intervals, making them suitable for inference on heterogeneous treatment effects.

3. Orthogonal Random Forests:
   Orthogonal random forests (Oprescu et al., 2019) combine the orthogonalization approach of double machine learning with the recursive partitioning of causal forests. This method is particularly useful for settings with high-dimensional nuisance parameters and treatment effect heterogeneity.

   The approach works by:
   - Using double machine learning to construct orthogonalized outcomes and treatments
   - Building trees based on the criterion of maximizing heterogeneity in treatment effects
   - Providing asymptotically valid confidence intervals for conditional average treatment effects

4. Deep Instrumental Variables:
   For settings where instrumental variables are available, deep instrumental variables (Hartford et al., 2017) use neural networks to model complex, non-linear relationships between instruments, treatments, and outcomes.

   The method involves:
   - A two-stage approach similar to 2SLS but using neural networks
   - Jointly training the first and second stage networks
   - Allowing for flexible, data-driven specification of the relationship between variables

Empirical Applications:
1. Labor Market Returns to Education:
   We apply double machine learning to estimate returns to education using data from the National Longitudinal Survey of Youth. By controlling for a high-dimensional set of potential confounders (family background, cognitive abilities, non-cognitive skills), we obtain more precise estimates of the causal effect of education on earnings.

   Our analysis reveals heterogeneous returns to education that vary by cognitive ability, family background, and local labor market conditions. These patterns of heterogeneity would be difficult to discover using traditional parametric approaches.

2. Policy Evaluation: Job Training Programs:
   Using causal forests, we revisit the evaluation of the Job Training Partnership Act (JTPA) program. Our analysis identifies subgroups with varying treatment effects, providing insights into the program's effectiveness across different demographic and socioeconomic characteristics.

   The results demonstrate that the program's impact was concentrated among participants with certain characteristics, suggesting potential improvements in targeting for future interventions.

3. Effect of Minimum Wage on Employment:
   We apply orthogonal random forests to estimate the heterogeneous effects of minimum wage increases on employment across different regions and industries. By incorporating high-dimensional controls for local economic conditions, industry composition, and demographic factors, we obtain more nuanced estimates than traditional approaches.

   Our findings suggest that minimum wage effects vary substantially based on local labor market conditions, industry concentration, and the initial wage distribution, with implications for targeted policy design.

Challenges and Limitations:
1. Interpretability:
   While machine learning methods can capture complex relationships, the resulting models may be less interpretable than traditional econometric approaches. This can make it challenging to communicate findings to policymakers and other stakeholders.

2. Computational Requirements:
   Many of the methods discussed require significant computational resources, especially for large datasets or complex models.

3. Robustness to Model Misspecification:
   Although these methods are more flexible than traditional approaches, they still rely on assumptions about the data-generating process. Sensitivity analysis and robustness checks remain important.

4. External Validity:
   As with any causal analysis, extrapolating findings to different contexts requires careful consideration of the underlying mechanisms and potential sources of heterogeneity.

Future Directions:
1. Integration with Structural Models:
   Combining machine learning approaches with structural economic models represents a promising direction for future research, allowing researchers to leverage the flexibility of machine learning while incorporating economic theory.

2. Bayesian Approaches:
   Bayesian machine learning methods for causal inference offer the potential to incorporate prior knowledge and provide a natural framework for uncertainty quantification.

3. Text and Unstructured Data:
   Extending these methods to incorporate text, images, and other unstructured data sources could open new avenues for economic research.

4. Causal Discovery:
   While this paper has focused on causal estimation given a causal structure, machine learning methods for causal discovery—identifying causal relationships from observational data—represent an exciting frontier.

Conclusion:
Machine learning methods for causal inference offer powerful tools for economic research, enabling more flexible modeling of complex relationships while maintaining the statistical guarantees necessary for valid causal conclusions. By combining the strengths of machine learning and econometrics, these approaches can enhance our understanding of economic phenomena and inform more effective policy design.

As these methods continue to develop, they have the potential to transform empirical economics, allowing researchers to address previously intractable questions and derive more nuanced insights from increasingly complex and high-dimensional data. However, their successful application requires careful consideration of their assumptions, limitations, and appropriate contexts for use.

Acknowledgments:
This research was supported by grants from the National Science Foundation and the Stanford Institute for Economic Policy Research.

References:
[1] Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., & Robins, J. (2018). Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal, 21(1), C1-C68.
[2] Wager, S., & Athey, S. (2018). Estimation and inference of heterogeneous treatment effects using random forests. Journal of the American Statistical Association, 113(523), 1228-1242.
[3] Oprescu, M., Syrgkanis, V., & Wu, Z. S. (2019). Orthogonal random forest for causal inference. Proceedings of the 36th International Conference on Machine Learning.
